Dataflow Mobres â€“ Smart Data Automation Pipeline

Author: Luiz Henrique Vieira
Role: Data Engineer | Senior Data | Performance Analyst
Status: Production-ready MVP

ğŸš€ Project Overview

dataflow_mobres is a professional-grade Data Engineering pipeline designed to automate the end-to-end ingestion, transformation, and refreshing of analytical data tables in a PostgreSQL environment. It efficiently handles deletion by date, file preparation, loading into staging or fact tables, and materialized view refresh â€” all from manually extracted .csv files.

ğŸ§° Technologies & Tools Used

Category

Technologies / Tools

Language

Python 3.13

Database

PostgreSQL (local, port 5433)

ML/Forecasting (Future)

XGBoost, LightGBM, Prophet (planned)

Scheduling (Future)

GitHub Actions, Windows Task Scheduler

Version Control

Git + GitHub

Virtual Environment

venv

Encoding Handling

cp1252 > UTF-8

CSV Processing

Python csv, custom cleaner

Logging & Debugging

Python logging

CI/CD (Planned)

GitHub Actions

Environment Config

python-dotenv (.env management)

ğŸ“‚ Project Structure

â”œâ”€â”€ .env                         # Environment variables (DB config)
â”œâ”€â”€ notebooks/                  # Notebooks for EDA or experimentation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ database/               # DB connection, delete, truncate, refresh
â”‚   â”œâ”€â”€ pipelines/              # Data pipelines (CSV to Postgres)
â”‚   â”œâ”€â”€ utils/                  # Helpers for file and data handling
â”‚   â”œâ”€â”€ models/                 # Reserved for ML models (planned)
â”‚   â””â”€â”€ files/                  # Reserved for file categorization
â”œâ”€â”€ tests/                      # Pytest test structure (coming soon)
â”œâ”€â”€ main.py                     # Entry point: executes full pipeline
â”œâ”€â”€ extrair_zipados.ipynb       # CSV extraction from VDI (manual step)
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # Project documentation

âœ… Features Implemented

ğŸ§ª Testing (Coming Soon)

Unit tests with pytest

Mocked PostgreSQL test environment

CI trigger for push and pull request on main branch

ğŸ§  Planned Features

Feature

Description

ğŸ” Scheduling

Auto-run pipeline daily or hourly

ğŸ§ª Test coverage

Full test suite on ingestion & DB operations

ğŸ“Š ML Forecasting

XGBoost / Prophet demand forecasting

ğŸ“¦ Dockerization

Containerize full app for portability

ğŸ§© FastAPI microservice

Endpoint to trigger pipeline on demand

â˜ï¸ Cloud Support

Deploy on AWS EC2 or RDS (Phase 2)

ğŸ§­ How to Run

Clone this repository:

git clone https://github.com/Luizheennryy/dataflow_mobres.git
cd dataflow_mobres

Create and activate your virtual environment:

python -m venv .venv
source .venv/Scripts/activate  # Windows

Install dependencies:

pip install -r requirements.txt

Set your environment variables in .env:

HOST=localhost
PORT=5433
USER=postgres
PASSWD=22
DATABASE=Projetos

Place updated CSVs in C:/Users/<user>/Desktop/Bases/

Run the pipeline:

python main.py

ğŸ¤ Contributing

Contributions are welcome. Please fork the repository, open a branch, and submit a PR. Testing and documentation improvements are especially appreciated!

ğŸ“© Contact

Luiz Henrique Dos Santos Vieira â€“ [LinkedIn](https://www.linkedin.com/in/luiz-henrique-santos-vieira/)

Feel free to reach out to discuss data projects, engineering roles, or collaborations.

ğŸ“Œ License

MIT â€“ feel free to use, modify and share with credit. âœ¨
